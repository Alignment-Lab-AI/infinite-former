nohup ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2-medium --model_type=gpt2-medium --config_name=vanilla --tokenizer_name=gpt2-medium --cache_dir=./vanilla --output_dir=./vanilla/checkpoints --train_file=./../transformer-xl/data/wikitext-103/train.txt --validation_file=./../transformer-xl/data/wikitext-103/valid.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 &

CUDA_VISIBLE_DEVICES=7 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=vanilla --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./vanilla/checkpoints_pg19 --train_file=/home/pam/pg19/train.txt --validation_file=/home/pam/pg19/val.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512

screen -dmS gpt2_mask_kl sh -c 'CUDA_VISIBLE_DEVICES=4 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=infinite_memory_transformer_mask_kl --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./infinite_memory_transformer_mask_kl/checkpoints_1 --train_file=./../transformer-xl/data/wikitext-103/train.txt --validation_file=./../transformer-xl/data/wikitext-103/valid.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --kl_regularizer --kl_m=.000001; exec bash'

CUDA_VISIBLE_DEVICES=7 ./examples/language-modeling/run_clm.py --model_name_or_path=./infinite_memory_transformer_mask_kl/checkpoints_1/checkpoint --model_type=gpt2 --config_name=infinite_memory_transformer_mask_kl --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./infinite_memory_transformer_mask_kl/checkpoints_1 --train_file=./../transformer-xl/data/wikitext-103/train.txt --validation_file=./../transformer-xl/data/wikitext-103/valid.txt --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --kl_regularizer --kl_m=.0005

screen -dmS gpt2_mask_kl sh -c 'CUDA_VISIBLE_DEVICES=4 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=infinite_memory_transformer_mask_kl --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./infinite_memory_transformer_mask_kl/checkpoints_1_lr0005 --train_file=./../transformer-xl/data/wikitext-103/train.txt --validation_file=./../transformer-xl/data/wikitext-103/valid.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --kl_regularizer --kl_m=.000001; exec bash'

screen -dmS gpt2_mask_kl_sticky_mem sh -c 'CUDA_VISIBLE_DEVICES=4 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=infinite_memory_transformer_mask_kl_sticky_mem --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./infinite_memory_transformer_mask_kl_sticky_mem/checkpoints_1 --train_file=./../transformer-xl/data/wikitext-103/train.txt --validation_file=./../transformer-xl/data/wikitext-103/valid.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --kl_regularizer --kl_m=.000001; exec bash'

screen -dmS gpt2_mask_kl_sticky_mem_pg19 sh -c 'CUDA_VISIBLE_DEVICES=3 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=infinite_memory_transformer_mask_kl_sticky_mem --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./infinite_memory_transformer_mask_kl_sticky_mem/checkpoints_pg19 --train_file=/home/pam/pg19/train.txt --validation_file=/home/pam/pg19/val.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --kl_regularizer --kl_m=.000001; exec bash'



CUDA_VISIBLE_DEVICES=3 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=compressive --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./compressive/checkpoints --train_file=./../transformer-xl/data/wikitext-103/train.txt --validation_file=./../transformer-xl/data/wikitext-103/valid.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --compressive



screen -dmS gpt2_mask_kl_pg19 sh -c 'CUDA_VISIBLE_DEVICES=2 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=./infinite_memory_transformer_mask_kl --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./infinite_memory_transformer_mask_kl/checkpoints_pg19_mem_5000 --train_file=/home/pam/pg19/train.txt --validation_file=/home/pam/pg19/test.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --kl_regularizer --kl_m=.000001; exec bash'
  
screen -dmS gpt2_mask_kl_sticky_mem_pg19 sh -c 'CUDA_VISIBLE_DEVICES=3 ./examples/language-modeling/run_clm.py --model_name_or_path=gpt2 --model_type=gpt2 --config_name=./infinite_memory_transformer_mask_kl_sticky_mem --tokenizer_name=gpt2 --cache_dir=./cache --output_dir=./infinite_memory_transformer_mask_kl_sticky_mem/checkpoints_pg19_mem_5000 --train_file=/home/pam/pg19/train.txt --validation_file=/home/pam/pg19/test.txt --do_train --do_eval --overwrite_output_dir --evaluation_strategy=steps --per_device_train_batch_size=1 --per_device_eval_batch_size=1 --block_size=512 --num_train_epochs=1 --kl_regularizer --kl_m=.000001; exec bash'